{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "1358faf7-20b3-4bfd-a685-52478c310965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38612935-8df2-4cb6-9b89-8f3ffa53919a",
   "metadata": {},
   "source": [
    "Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "e768b1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BRCA1_genomic</th>\n",
       "      <th>BRCA1_transcriptomic</th>\n",
       "      <th>BRCA1_proteomic</th>\n",
       "      <th>BRCA2_genomic</th>\n",
       "      <th>BRCA2_transcriptomic</th>\n",
       "      <th>BRCA2_proteomic</th>\n",
       "      <th>TP53_genomic</th>\n",
       "      <th>TP53_transcriptomic</th>\n",
       "      <th>...</th>\n",
       "      <th>SMAD4_proteomic</th>\n",
       "      <th>resistance_label</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>chemotherapy_type</th>\n",
       "      <th>treatment_duration</th>\n",
       "      <th>tumor_grade</th>\n",
       "      <th>tumor_stage</th>\n",
       "      <th>clinical_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>-1.232540</td>\n",
       "      <td>-0.684492</td>\n",
       "      <td>0.457324</td>\n",
       "      <td>2.098221</td>\n",
       "      <td>-0.138082</td>\n",
       "      <td>0.591136</td>\n",
       "      <td>-0.106971</td>\n",
       "      <td>1.942246</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.331638</td>\n",
       "      <td>resistant</td>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Progression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>-2.403669</td>\n",
       "      <td>1.392456</td>\n",
       "      <td>0.672293</td>\n",
       "      <td>-1.500477</td>\n",
       "      <td>-1.478777</td>\n",
       "      <td>1.672266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.834185</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.157195</td>\n",
       "      <td>resistant</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Progression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>450</td>\n",
       "      <td>450</td>\n",
       "      <td>0.765402</td>\n",
       "      <td>1.073413</td>\n",
       "      <td>0.498690</td>\n",
       "      <td>-1.942498</td>\n",
       "      <td>-0.155422</td>\n",
       "      <td>-1.155708</td>\n",
       "      <td>-0.202606</td>\n",
       "      <td>0.980004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Progression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>903</td>\n",
       "      <td>903</td>\n",
       "      <td>0.139351</td>\n",
       "      <td>-0.633330</td>\n",
       "      <td>-0.616855</td>\n",
       "      <td>0.846722</td>\n",
       "      <td>0.984656</td>\n",
       "      <td>0.783823</td>\n",
       "      <td>0.792962</td>\n",
       "      <td>0.569030</td>\n",
       "      <td>...</td>\n",
       "      <td>2.151323</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>71</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Regimen A</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>2.093198</td>\n",
       "      <td>-1.511883</td>\n",
       "      <td>1.159381</td>\n",
       "      <td>0.973102</td>\n",
       "      <td>-0.779093</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>-0.457633</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233309</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  BRCA1_genomic  BRCA1_transcriptomic  \\\n",
       "4995           289         289      -1.232540             -0.684492   \n",
       "4996           294         294      -2.403669              1.392456   \n",
       "4997           450         450       0.765402              1.073413   \n",
       "4998           903         903       0.139351             -0.633330   \n",
       "4999           214         214       2.093198             -1.511883   \n",
       "\n",
       "      BRCA1_proteomic  BRCA2_genomic  BRCA2_transcriptomic  BRCA2_proteomic  \\\n",
       "4995         0.457324       2.098221             -0.138082         0.591136   \n",
       "4996         0.672293      -1.500477             -1.478777         1.672266   \n",
       "4997         0.498690      -1.942498             -0.155422        -1.155708   \n",
       "4998        -0.616855       0.846722              0.984656         0.783823   \n",
       "4999         1.159381       0.973102             -0.779093         0.203236   \n",
       "\n",
       "      TP53_genomic  TP53_transcriptomic  ...  SMAD4_proteomic  \\\n",
       "4995     -0.106971             1.942246  ...        -2.331638   \n",
       "4996           NaN            -0.834185  ...        -1.157195   \n",
       "4997     -0.202606             0.980004  ...        -0.255624   \n",
       "4998      0.792962             0.569030  ...         2.151323   \n",
       "4999     -0.457633             0.185689  ...        -0.233309   \n",
       "\n",
       "      resistance_label  age  gender  ethnicity  chemotherapy_type  \\\n",
       "4995         resistant   48  Female      Asian          Regimen C   \n",
       "4996         resistant   53    Male   Hispanic          Regimen C   \n",
       "4997               NaN   69  Female      Black          Regimen C   \n",
       "4998         sensitive   71    Male   Hispanic          Regimen A   \n",
       "4999         sensitive   46    Male   Hispanic          Regimen C   \n",
       "\n",
       "      treatment_duration  tumor_grade  tumor_stage  clinical_outcome  \n",
       "4995                   4            4    Stage III       Progression  \n",
       "4996                   3            4    Stage III       Progression  \n",
       "4997                  10            3      Stage I       Progression  \n",
       "4998                   5            1    Stage III            Stable  \n",
       "4999                   6            2      Stage I            Stable  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Extended_Multi-Omics_Dataset__5000_samples_.csv\")\n",
    "df.head(10)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "c6867783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping unnesseray columns \n",
    "df=df.drop('Unnamed: 0',axis=1)\n",
    "df=df.drop('tumor_grade',axis=1)\n",
    "df=df.drop('Unnamed: 0.1',axis=1)\n",
    "# temp for just checking missing valuse in clinical data\n",
    "temp=df[['resistance_label', 'age',\n",
    "       'gender', 'ethnicity', 'chemotherapy_type', 'treatment_duration',\n",
    "       'tumor_stage', 'clinical_outcome']]\n",
    "#all numirical genomic data\n",
    "x=df.iloc[:,:60]\n",
    "original_columns=x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "4f6c1fbb-63bd-48ec-bcf2-ea3c3e162429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRCA1_genomic</th>\n",
       "      <th>BRCA1_transcriptomic</th>\n",
       "      <th>BRCA1_proteomic</th>\n",
       "      <th>BRCA2_genomic</th>\n",
       "      <th>BRCA2_transcriptomic</th>\n",
       "      <th>BRCA2_proteomic</th>\n",
       "      <th>TP53_genomic</th>\n",
       "      <th>TP53_transcriptomic</th>\n",
       "      <th>TP53_proteomic</th>\n",
       "      <th>ATM_genomic</th>\n",
       "      <th>...</th>\n",
       "      <th>CDH1_proteomic</th>\n",
       "      <th>ARID1A_genomic</th>\n",
       "      <th>ARID1A_transcriptomic</th>\n",
       "      <th>ARID1A_proteomic</th>\n",
       "      <th>KRAS_genomic</th>\n",
       "      <th>KRAS_transcriptomic</th>\n",
       "      <th>KRAS_proteomic</th>\n",
       "      <th>SMAD4_genomic</th>\n",
       "      <th>SMAD4_transcriptomic</th>\n",
       "      <th>SMAD4_proteomic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.694713</td>\n",
       "      <td>-0.409282</td>\n",
       "      <td>-0.524088</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.121031</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>-0.327895</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>-1.208506</td>\n",
       "      <td>0.299469</td>\n",
       "      <td>1.002222</td>\n",
       "      <td>0.593181</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.565291</td>\n",
       "      <td>-0.223245</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>1.347181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592025</td>\n",
       "      <td>-0.587738</td>\n",
       "      <td>-1.443201</td>\n",
       "      <td>0.638187</td>\n",
       "      <td>1.744311</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.409141</td>\n",
       "      <td>1.414841</td>\n",
       "      <td>-0.874199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.538794</td>\n",
       "      <td>-0.057381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056715</td>\n",
       "      <td>-0.979691</td>\n",
       "      <td>0.415395</td>\n",
       "      <td>-0.175845</td>\n",
       "      <td>0.812034</td>\n",
       "      <td>-0.615397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269784</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>-1.025943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.334827</td>\n",
       "      <td>-0.124077</td>\n",
       "      <td>1.636105</td>\n",
       "      <td>0.822859</td>\n",
       "      <td>-0.923119</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292375</td>\n",
       "      <td>-0.047902</td>\n",
       "      <td>1.698181</td>\n",
       "      <td>-0.379144</td>\n",
       "      <td>0.561112</td>\n",
       "      <td>0.349701</td>\n",
       "      <td>0.062074</td>\n",
       "      <td>-0.958112</td>\n",
       "      <td>0.523665</td>\n",
       "      <td>-1.925637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.187765</td>\n",
       "      <td>-0.397323</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>0.091094</td>\n",
       "      <td>-0.851540</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>-1.531535</td>\n",
       "      <td>1.150267</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>1.118550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661383</td>\n",
       "      <td>-2.662336</td>\n",
       "      <td>0.540007</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.497026</td>\n",
       "      <td>-1.928427</td>\n",
       "      <td>0.292830</td>\n",
       "      <td>-0.542501</td>\n",
       "      <td>1.602190</td>\n",
       "      <td>0.361721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.412615</td>\n",
       "      <td>0.784604</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.262891</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.180813</td>\n",
       "      <td>1.114322</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>0.718186</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.155470</td>\n",
       "      <td>-0.495627</td>\n",
       "      <td>1.296774</td>\n",
       "      <td>-0.885340</td>\n",
       "      <td>-1.536663</td>\n",
       "      <td>0.987496</td>\n",
       "      <td>-0.218814</td>\n",
       "      <td>1.271249</td>\n",
       "      <td>1.470893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-1.232540</td>\n",
       "      <td>-0.684492</td>\n",
       "      <td>0.457324</td>\n",
       "      <td>2.098221</td>\n",
       "      <td>-0.138082</td>\n",
       "      <td>0.591136</td>\n",
       "      <td>-0.106971</td>\n",
       "      <td>1.942246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>...</td>\n",
       "      <td>2.202952</td>\n",
       "      <td>-0.957253</td>\n",
       "      <td>0.539574</td>\n",
       "      <td>0.288545</td>\n",
       "      <td>0.528159</td>\n",
       "      <td>-0.284904</td>\n",
       "      <td>-0.592256</td>\n",
       "      <td>0.226493</td>\n",
       "      <td>-0.456029</td>\n",
       "      <td>-2.331638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-2.403669</td>\n",
       "      <td>1.392456</td>\n",
       "      <td>0.672293</td>\n",
       "      <td>-1.500477</td>\n",
       "      <td>-1.478777</td>\n",
       "      <td>1.672266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.834185</td>\n",
       "      <td>-2.266052</td>\n",
       "      <td>-0.350778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>-0.070926</td>\n",
       "      <td>-0.941599</td>\n",
       "      <td>0.517374</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>1.050505</td>\n",
       "      <td>0.133337</td>\n",
       "      <td>-1.437188</td>\n",
       "      <td>-0.496744</td>\n",
       "      <td>-1.157195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.765402</td>\n",
       "      <td>1.073413</td>\n",
       "      <td>0.498690</td>\n",
       "      <td>-1.942498</td>\n",
       "      <td>-0.155422</td>\n",
       "      <td>-1.155708</td>\n",
       "      <td>-0.202606</td>\n",
       "      <td>0.980004</td>\n",
       "      <td>0.305151</td>\n",
       "      <td>1.148091</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.633039</td>\n",
       "      <td>1.064273</td>\n",
       "      <td>1.706536</td>\n",
       "      <td>1.283887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.539460</td>\n",
       "      <td>0.357451</td>\n",
       "      <td>-1.319617</td>\n",
       "      <td>-0.521895</td>\n",
       "      <td>-0.255624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.139351</td>\n",
       "      <td>-0.633330</td>\n",
       "      <td>-0.616855</td>\n",
       "      <td>0.846722</td>\n",
       "      <td>0.984656</td>\n",
       "      <td>0.783823</td>\n",
       "      <td>0.792962</td>\n",
       "      <td>0.569030</td>\n",
       "      <td>0.131523</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416154</td>\n",
       "      <td>0.070638</td>\n",
       "      <td>-0.049535</td>\n",
       "      <td>-1.450612</td>\n",
       "      <td>-0.529286</td>\n",
       "      <td>-0.258399</td>\n",
       "      <td>1.859715</td>\n",
       "      <td>-0.160022</td>\n",
       "      <td>0.273241</td>\n",
       "      <td>2.151323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2.093198</td>\n",
       "      <td>-1.511883</td>\n",
       "      <td>1.159381</td>\n",
       "      <td>0.973102</td>\n",
       "      <td>-0.779093</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>-0.457633</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>1.509131</td>\n",
       "      <td>0.605606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682287</td>\n",
       "      <td>-0.426561</td>\n",
       "      <td>-1.624860</td>\n",
       "      <td>-0.077222</td>\n",
       "      <td>0.801357</td>\n",
       "      <td>0.492039</td>\n",
       "      <td>1.814402</td>\n",
       "      <td>-0.253188</td>\n",
       "      <td>-0.160752</td>\n",
       "      <td>-0.233309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRCA1_genomic  BRCA1_transcriptomic  BRCA1_proteomic  BRCA2_genomic  \\\n",
       "0         -0.694713             -0.409282        -0.524088       0.152355   \n",
       "1          1.592025             -0.587738        -1.443201       0.638187   \n",
       "2          0.269784              0.011594        -1.025943            NaN   \n",
       "3         -1.187765             -0.397323         0.534365       0.091094   \n",
       "4          2.412615              0.784604        -0.019260      -0.262891   \n",
       "...             ...                   ...              ...            ...   \n",
       "4995      -1.232540             -0.684492         0.457324       2.098221   \n",
       "4996      -2.403669              1.392456         0.672293      -1.500477   \n",
       "4997       0.765402              1.073413         0.498690      -1.942498   \n",
       "4998       0.139351             -0.633330        -0.616855       0.846722   \n",
       "4999       2.093198             -1.511883         1.159381       0.973102   \n",
       "\n",
       "      BRCA2_transcriptomic  BRCA2_proteomic  TP53_genomic  \\\n",
       "0                      NaN         1.121031      0.000207   \n",
       "1                 1.744311         0.663598      0.204798   \n",
       "2                -1.334827        -0.124077      1.636105   \n",
       "3                -0.851540         0.006273     -1.531535   \n",
       "4                 0.022466              NaN     -1.180813   \n",
       "...                    ...              ...           ...   \n",
       "4995             -0.138082         0.591136     -0.106971   \n",
       "4996             -1.478777         1.672266           NaN   \n",
       "4997             -0.155422        -1.155708     -0.202606   \n",
       "4998              0.984656         0.783823      0.792962   \n",
       "4999             -0.779093         0.203236     -0.457633   \n",
       "\n",
       "      TP53_transcriptomic  TP53_proteomic  ATM_genomic  ...  CDH1_proteomic  \\\n",
       "0               -0.009300       -0.327895     0.155191  ...       -0.010190   \n",
       "1                0.409141        1.414841    -0.874199  ...       -1.538794   \n",
       "2                0.822859       -0.923119    -0.072429  ...       -0.292375   \n",
       "3                1.150267       -0.205284     1.118550  ...        0.661383   \n",
       "4                1.114322        0.715381     0.718186  ...             NaN   \n",
       "...                   ...             ...          ...  ...             ...   \n",
       "4995             1.942246             NaN     0.094621  ...        2.202952   \n",
       "4996            -0.834185       -2.266052    -0.350778  ...        0.956554   \n",
       "4997             0.980004        0.305151     1.148091  ...       -1.633039   \n",
       "4998             0.569030        0.131523    -0.175380  ...       -0.416154   \n",
       "4999             0.185689        1.509131     0.605606  ...        0.682287   \n",
       "\n",
       "      ARID1A_genomic  ARID1A_transcriptomic  ARID1A_proteomic  KRAS_genomic  \\\n",
       "0          -1.208506               0.299469          1.002222      0.593181   \n",
       "1          -0.057381                    NaN          1.056715     -0.979691   \n",
       "2          -0.047902               1.698181         -0.379144      0.561112   \n",
       "3          -2.662336               0.540007          0.313300      0.497026   \n",
       "4           2.155470              -0.495627          1.296774     -0.885340   \n",
       "...              ...                    ...               ...           ...   \n",
       "4995       -0.957253               0.539574          0.288545      0.528159   \n",
       "4996       -0.070926              -0.941599          0.517374      0.001503   \n",
       "4997        1.064273               1.706536          1.283887           NaN   \n",
       "4998        0.070638              -0.049535         -1.450612     -0.529286   \n",
       "4999       -0.426561              -1.624860         -0.077222      0.801357   \n",
       "\n",
       "      KRAS_transcriptomic  KRAS_proteomic  SMAD4_genomic  \\\n",
       "0                0.059304        0.565291      -0.223245   \n",
       "1                0.415395       -0.175845       0.812034   \n",
       "2                0.349701        0.062074      -0.958112   \n",
       "3               -1.928427        0.292830      -0.542501   \n",
       "4               -1.536663        0.987496      -0.218814   \n",
       "...                   ...             ...            ...   \n",
       "4995            -0.284904       -0.592256       0.226493   \n",
       "4996             1.050505        0.133337      -1.437188   \n",
       "4997             1.539460        0.357451      -1.319617   \n",
       "4998            -0.258399        1.859715      -0.160022   \n",
       "4999             0.492039        1.814402      -0.253188   \n",
       "\n",
       "      SMAD4_transcriptomic  SMAD4_proteomic  \n",
       "0                 1.044175         1.347181  \n",
       "1                -0.615397              NaN  \n",
       "2                 0.523665        -1.925637  \n",
       "3                 1.602190         0.361721  \n",
       "4                 1.271249         1.470893  \n",
       "...                    ...              ...  \n",
       "4995             -0.456029        -2.331638  \n",
       "4996             -0.496744        -1.157195  \n",
       "4997             -0.521895        -0.255624  \n",
       "4998              0.273241         2.151323  \n",
       "4999             -0.160752        -0.233309  \n",
       "\n",
       "[5000 rows x 60 columns]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "be9703b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resistance_label      174\n",
       "age                     0\n",
       "gender                  0\n",
       "ethnicity               0\n",
       "chemotherapy_type       0\n",
       "treatment_duration      0\n",
       "tumor_stage             0\n",
       "clinical_outcome        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "0fcd4664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BRCA1_genomic', 'BRCA1_transcriptomic', 'BRCA1_proteomic',\n",
       "       'BRCA2_genomic', 'BRCA2_transcriptomic', 'BRCA2_proteomic',\n",
       "       'TP53_genomic', 'TP53_transcriptomic', 'TP53_proteomic', 'ATM_genomic',\n",
       "       'ATM_transcriptomic', 'ATM_proteomic', 'CHEK2_genomic',\n",
       "       'CHEK2_transcriptomic', 'CHEK2_proteomic', 'PALB2_genomic',\n",
       "       'PALB2_transcriptomic', 'PALB2_proteomic', 'BARD1_genomic',\n",
       "       'BARD1_transcriptomic', 'BARD1_proteomic', 'MRE11A_genomic',\n",
       "       'MRE11A_transcriptomic', 'MRE11A_proteomic', 'RAD51_genomic',\n",
       "       'RAD51_transcriptomic', 'RAD51_proteomic', 'ERBB2_genomic',\n",
       "       'ERBB2_transcriptomic', 'ERBB2_proteomic', 'PIK3CA_genomic',\n",
       "       'PIK3CA_transcriptomic', 'PIK3CA_proteomic', 'AKT1_genomic',\n",
       "       'AKT1_transcriptomic', 'AKT1_proteomic', 'PTEN_genomic',\n",
       "       'PTEN_transcriptomic', 'PTEN_proteomic', 'MAPK1_genomic',\n",
       "       'MAPK1_transcriptomic', 'MAPK1_proteomic', 'ESR1_genomic',\n",
       "       'ESR1_transcriptomic', 'ESR1_proteomic', 'FGFR1_genomic',\n",
       "       'FGFR1_transcriptomic', 'FGFR1_proteomic', 'CDH1_genomic',\n",
       "       'CDH1_transcriptomic', 'CDH1_proteomic', 'ARID1A_genomic',\n",
       "       'ARID1A_transcriptomic', 'ARID1A_proteomic', 'KRAS_genomic',\n",
       "       'KRAS_transcriptomic', 'KRAS_proteomic', 'SMAD4_genomic',\n",
       "       'SMAD4_transcriptomic', 'SMAD4_proteomic', 'resistance_label', 'age',\n",
       "       'gender', 'ethnicity', 'chemotherapy_type', 'treatment_duration',\n",
       "       'tumor_stage', 'clinical_outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "8ac31aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       sensitive\n",
       "1       sensitive\n",
       "2       resistant\n",
       "3       resistant\n",
       "4       sensitive\n",
       "          ...    \n",
       "4995    resistant\n",
       "4996    resistant\n",
       "4997          NaN\n",
       "4998    sensitive\n",
       "4999    sensitive\n",
       "Name: resistance_label, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"resistance_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "67872c10-d933-415d-8a69-8c3e8ccea6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRCA1_genomic</th>\n",
       "      <th>BRCA1_transcriptomic</th>\n",
       "      <th>BRCA1_proteomic</th>\n",
       "      <th>BRCA2_genomic</th>\n",
       "      <th>BRCA2_transcriptomic</th>\n",
       "      <th>BRCA2_proteomic</th>\n",
       "      <th>TP53_genomic</th>\n",
       "      <th>TP53_transcriptomic</th>\n",
       "      <th>TP53_proteomic</th>\n",
       "      <th>ATM_genomic</th>\n",
       "      <th>...</th>\n",
       "      <th>SMAD4_transcriptomic</th>\n",
       "      <th>SMAD4_proteomic</th>\n",
       "      <th>resistance_label</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>chemotherapy_type</th>\n",
       "      <th>treatment_duration</th>\n",
       "      <th>tumor_stage</th>\n",
       "      <th>clinical_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.694713</td>\n",
       "      <td>-0.409282</td>\n",
       "      <td>-0.524088</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.121031</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>-0.327895</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>1.347181</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Regimen A</td>\n",
       "      <td>7</td>\n",
       "      <td>Stage IV</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592025</td>\n",
       "      <td>-0.587738</td>\n",
       "      <td>-1.443201</td>\n",
       "      <td>0.638187</td>\n",
       "      <td>1.744311</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.409141</td>\n",
       "      <td>1.414841</td>\n",
       "      <td>-0.874199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>72</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>10</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Progression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269784</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>-1.025943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.334827</td>\n",
       "      <td>-0.124077</td>\n",
       "      <td>1.636105</td>\n",
       "      <td>0.822859</td>\n",
       "      <td>-0.923119</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523665</td>\n",
       "      <td>-1.925637</td>\n",
       "      <td>resistant</td>\n",
       "      <td>71</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Regimen A</td>\n",
       "      <td>11</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.187765</td>\n",
       "      <td>-0.397323</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>0.091094</td>\n",
       "      <td>-0.851540</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>-1.531535</td>\n",
       "      <td>1.150267</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>1.118550</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602190</td>\n",
       "      <td>0.361721</td>\n",
       "      <td>resistant</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Regimen B</td>\n",
       "      <td>3</td>\n",
       "      <td>Stage II</td>\n",
       "      <td>Remission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.412615</td>\n",
       "      <td>0.784604</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.262891</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.180813</td>\n",
       "      <td>1.114322</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>0.718186</td>\n",
       "      <td>...</td>\n",
       "      <td>1.271249</td>\n",
       "      <td>1.470893</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>4</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-1.232540</td>\n",
       "      <td>-0.684492</td>\n",
       "      <td>0.457324</td>\n",
       "      <td>2.098221</td>\n",
       "      <td>-0.138082</td>\n",
       "      <td>0.591136</td>\n",
       "      <td>-0.106971</td>\n",
       "      <td>1.942246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456029</td>\n",
       "      <td>-2.331638</td>\n",
       "      <td>resistant</td>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>4</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Progression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-2.403669</td>\n",
       "      <td>1.392456</td>\n",
       "      <td>0.672293</td>\n",
       "      <td>-1.500477</td>\n",
       "      <td>-1.478777</td>\n",
       "      <td>1.672266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.834185</td>\n",
       "      <td>-2.266052</td>\n",
       "      <td>-0.350778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496744</td>\n",
       "      <td>-1.157195</td>\n",
       "      <td>resistant</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>3</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Progression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.765402</td>\n",
       "      <td>1.073413</td>\n",
       "      <td>0.498690</td>\n",
       "      <td>-1.942498</td>\n",
       "      <td>-0.155422</td>\n",
       "      <td>-1.155708</td>\n",
       "      <td>-0.202606</td>\n",
       "      <td>0.980004</td>\n",
       "      <td>0.305151</td>\n",
       "      <td>1.148091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521895</td>\n",
       "      <td>-0.255624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>10</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Progression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.139351</td>\n",
       "      <td>-0.633330</td>\n",
       "      <td>-0.616855</td>\n",
       "      <td>0.846722</td>\n",
       "      <td>0.984656</td>\n",
       "      <td>0.783823</td>\n",
       "      <td>0.792962</td>\n",
       "      <td>0.569030</td>\n",
       "      <td>0.131523</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273241</td>\n",
       "      <td>2.151323</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>71</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Regimen A</td>\n",
       "      <td>5</td>\n",
       "      <td>Stage III</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2.093198</td>\n",
       "      <td>-1.511883</td>\n",
       "      <td>1.159381</td>\n",
       "      <td>0.973102</td>\n",
       "      <td>-0.779093</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>-0.457633</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>1.509131</td>\n",
       "      <td>0.605606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160752</td>\n",
       "      <td>-0.233309</td>\n",
       "      <td>sensitive</td>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Regimen C</td>\n",
       "      <td>6</td>\n",
       "      <td>Stage I</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRCA1_genomic  BRCA1_transcriptomic  BRCA1_proteomic  BRCA2_genomic  \\\n",
       "0         -0.694713             -0.409282        -0.524088       0.152355   \n",
       "1          1.592025             -0.587738        -1.443201       0.638187   \n",
       "2          0.269784              0.011594        -1.025943            NaN   \n",
       "3         -1.187765             -0.397323         0.534365       0.091094   \n",
       "4          2.412615              0.784604        -0.019260      -0.262891   \n",
       "...             ...                   ...              ...            ...   \n",
       "4995      -1.232540             -0.684492         0.457324       2.098221   \n",
       "4996      -2.403669              1.392456         0.672293      -1.500477   \n",
       "4997       0.765402              1.073413         0.498690      -1.942498   \n",
       "4998       0.139351             -0.633330        -0.616855       0.846722   \n",
       "4999       2.093198             -1.511883         1.159381       0.973102   \n",
       "\n",
       "      BRCA2_transcriptomic  BRCA2_proteomic  TP53_genomic  \\\n",
       "0                      NaN         1.121031      0.000207   \n",
       "1                 1.744311         0.663598      0.204798   \n",
       "2                -1.334827        -0.124077      1.636105   \n",
       "3                -0.851540         0.006273     -1.531535   \n",
       "4                 0.022466              NaN     -1.180813   \n",
       "...                    ...              ...           ...   \n",
       "4995             -0.138082         0.591136     -0.106971   \n",
       "4996             -1.478777         1.672266           NaN   \n",
       "4997             -0.155422        -1.155708     -0.202606   \n",
       "4998              0.984656         0.783823      0.792962   \n",
       "4999             -0.779093         0.203236     -0.457633   \n",
       "\n",
       "      TP53_transcriptomic  TP53_proteomic  ATM_genomic  ...  \\\n",
       "0               -0.009300       -0.327895     0.155191  ...   \n",
       "1                0.409141        1.414841    -0.874199  ...   \n",
       "2                0.822859       -0.923119    -0.072429  ...   \n",
       "3                1.150267       -0.205284     1.118550  ...   \n",
       "4                1.114322        0.715381     0.718186  ...   \n",
       "...                   ...             ...          ...  ...   \n",
       "4995             1.942246             NaN     0.094621  ...   \n",
       "4996            -0.834185       -2.266052    -0.350778  ...   \n",
       "4997             0.980004        0.305151     1.148091  ...   \n",
       "4998             0.569030        0.131523    -0.175380  ...   \n",
       "4999             0.185689        1.509131     0.605606  ...   \n",
       "\n",
       "      SMAD4_transcriptomic  SMAD4_proteomic  resistance_label  age  gender  \\\n",
       "0                 1.044175         1.347181         sensitive   30    Male   \n",
       "1                -0.615397              NaN         sensitive   72  Female   \n",
       "2                 0.523665        -1.925637         resistant   71    Male   \n",
       "3                 1.602190         0.361721         resistant   60  Female   \n",
       "4                 1.271249         1.470893         sensitive   40    Male   \n",
       "...                    ...              ...               ...  ...     ...   \n",
       "4995             -0.456029        -2.331638         resistant   48  Female   \n",
       "4996             -0.496744        -1.157195         resistant   53    Male   \n",
       "4997             -0.521895        -0.255624               NaN   69  Female   \n",
       "4998              0.273241         2.151323         sensitive   71    Male   \n",
       "4999             -0.160752        -0.233309         sensitive   46    Male   \n",
       "\n",
       "      ethnicity  chemotherapy_type  treatment_duration  tumor_stage  \\\n",
       "0     Caucasian          Regimen A                   7     Stage IV   \n",
       "1         Asian          Regimen C                  10    Stage III   \n",
       "2         Asian          Regimen A                  11      Stage I   \n",
       "3         Black          Regimen B                   3     Stage II   \n",
       "4         Black          Regimen C                   4      Stage I   \n",
       "...         ...                ...                 ...          ...   \n",
       "4995      Asian          Regimen C                   4    Stage III   \n",
       "4996   Hispanic          Regimen C                   3    Stage III   \n",
       "4997      Black          Regimen C                  10      Stage I   \n",
       "4998   Hispanic          Regimen A                   5    Stage III   \n",
       "4999   Hispanic          Regimen C                   6      Stage I   \n",
       "\n",
       "      clinical_outcome  \n",
       "0               Stable  \n",
       "1          Progression  \n",
       "2               Stable  \n",
       "3            Remission  \n",
       "4               Stable  \n",
       "...                ...  \n",
       "4995       Progression  \n",
       "4996       Progression  \n",
       "4997       Progression  \n",
       "4998            Stable  \n",
       "4999            Stable  \n",
       "\n",
       "[5000 rows x 68 columns]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "60ce968c-a176-4f90-8732-015088f45050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"resistance_label\",axis=1)\n",
    "y=df[\"resistance_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "337386ec-e50c-4934-9472-55dfa1ff69fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRCA1_genomic           169\n",
       "BRCA1_transcriptomic    163\n",
       "BRCA1_proteomic         163\n",
       "BRCA2_genomic           149\n",
       "BRCA2_transcriptomic    102\n",
       "                       ... \n",
       "ethnicity                 0\n",
       "chemotherapy_type         0\n",
       "treatment_duration        0\n",
       "tumor_stage               0\n",
       "clinical_outcome          0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "ffdb3e34-e9ba-4eb8-87d6-f1dccdb0be0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRCA1_genomic</th>\n",
       "      <th>BRCA1_transcriptomic</th>\n",
       "      <th>BRCA1_proteomic</th>\n",
       "      <th>BRCA2_genomic</th>\n",
       "      <th>BRCA2_transcriptomic</th>\n",
       "      <th>BRCA2_proteomic</th>\n",
       "      <th>TP53_genomic</th>\n",
       "      <th>TP53_transcriptomic</th>\n",
       "      <th>TP53_proteomic</th>\n",
       "      <th>ATM_genomic</th>\n",
       "      <th>...</th>\n",
       "      <th>CDH1_proteomic</th>\n",
       "      <th>ARID1A_genomic</th>\n",
       "      <th>ARID1A_transcriptomic</th>\n",
       "      <th>ARID1A_proteomic</th>\n",
       "      <th>KRAS_genomic</th>\n",
       "      <th>KRAS_transcriptomic</th>\n",
       "      <th>KRAS_proteomic</th>\n",
       "      <th>SMAD4_genomic</th>\n",
       "      <th>SMAD4_transcriptomic</th>\n",
       "      <th>SMAD4_proteomic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.694713</td>\n",
       "      <td>-0.409282</td>\n",
       "      <td>-0.524088</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>0.242705</td>\n",
       "      <td>1.121031</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>-0.327895</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>-1.208506</td>\n",
       "      <td>0.299469</td>\n",
       "      <td>1.002222</td>\n",
       "      <td>0.593181</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.565291</td>\n",
       "      <td>-0.223245</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>1.347181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592025</td>\n",
       "      <td>-0.587738</td>\n",
       "      <td>-1.443201</td>\n",
       "      <td>0.638187</td>\n",
       "      <td>1.744311</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.409141</td>\n",
       "      <td>1.414841</td>\n",
       "      <td>-0.874199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.538794</td>\n",
       "      <td>-0.057381</td>\n",
       "      <td>0.216725</td>\n",
       "      <td>1.056715</td>\n",
       "      <td>-0.979691</td>\n",
       "      <td>0.415395</td>\n",
       "      <td>-0.175845</td>\n",
       "      <td>0.812034</td>\n",
       "      <td>-0.615397</td>\n",
       "      <td>0.401048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269784</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>-1.025943</td>\n",
       "      <td>0.034849</td>\n",
       "      <td>-1.334827</td>\n",
       "      <td>-0.124077</td>\n",
       "      <td>1.636105</td>\n",
       "      <td>0.822859</td>\n",
       "      <td>-0.923119</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292375</td>\n",
       "      <td>-0.047902</td>\n",
       "      <td>1.698181</td>\n",
       "      <td>-0.379144</td>\n",
       "      <td>0.561112</td>\n",
       "      <td>0.349701</td>\n",
       "      <td>0.062074</td>\n",
       "      <td>-0.958112</td>\n",
       "      <td>0.523665</td>\n",
       "      <td>-1.925637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.187765</td>\n",
       "      <td>-0.397323</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>0.091094</td>\n",
       "      <td>-0.851540</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>-1.531535</td>\n",
       "      <td>1.150267</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>1.118550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661383</td>\n",
       "      <td>-2.662336</td>\n",
       "      <td>0.540007</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.497026</td>\n",
       "      <td>-1.928427</td>\n",
       "      <td>0.292830</td>\n",
       "      <td>-0.542501</td>\n",
       "      <td>1.602190</td>\n",
       "      <td>0.361721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.412615</td>\n",
       "      <td>0.784604</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.262891</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>-1.180813</td>\n",
       "      <td>1.114322</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>0.718186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032811</td>\n",
       "      <td>2.155470</td>\n",
       "      <td>-0.495627</td>\n",
       "      <td>1.296774</td>\n",
       "      <td>-0.885340</td>\n",
       "      <td>-1.536663</td>\n",
       "      <td>0.987496</td>\n",
       "      <td>-0.218814</td>\n",
       "      <td>1.271249</td>\n",
       "      <td>1.470893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-1.232540</td>\n",
       "      <td>-0.684492</td>\n",
       "      <td>0.457324</td>\n",
       "      <td>2.098221</td>\n",
       "      <td>-0.138082</td>\n",
       "      <td>0.591136</td>\n",
       "      <td>-0.106971</td>\n",
       "      <td>1.942246</td>\n",
       "      <td>-0.203036</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>...</td>\n",
       "      <td>2.202952</td>\n",
       "      <td>-0.957253</td>\n",
       "      <td>0.539574</td>\n",
       "      <td>0.288545</td>\n",
       "      <td>0.528159</td>\n",
       "      <td>-0.284904</td>\n",
       "      <td>-0.592256</td>\n",
       "      <td>0.226493</td>\n",
       "      <td>-0.456029</td>\n",
       "      <td>-2.331638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-2.403669</td>\n",
       "      <td>1.392456</td>\n",
       "      <td>0.672293</td>\n",
       "      <td>-1.500477</td>\n",
       "      <td>-1.478777</td>\n",
       "      <td>1.672266</td>\n",
       "      <td>0.583625</td>\n",
       "      <td>-0.834185</td>\n",
       "      <td>-2.266052</td>\n",
       "      <td>-0.350778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>-0.070926</td>\n",
       "      <td>-0.941599</td>\n",
       "      <td>0.517374</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>1.050505</td>\n",
       "      <td>0.133337</td>\n",
       "      <td>-1.437188</td>\n",
       "      <td>-0.496744</td>\n",
       "      <td>-1.157195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.765402</td>\n",
       "      <td>1.073413</td>\n",
       "      <td>0.498690</td>\n",
       "      <td>-1.942498</td>\n",
       "      <td>-0.155422</td>\n",
       "      <td>-1.155708</td>\n",
       "      <td>-0.202606</td>\n",
       "      <td>0.980004</td>\n",
       "      <td>0.305151</td>\n",
       "      <td>1.148091</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.633039</td>\n",
       "      <td>1.064273</td>\n",
       "      <td>1.706536</td>\n",
       "      <td>1.283887</td>\n",
       "      <td>0.271824</td>\n",
       "      <td>1.539460</td>\n",
       "      <td>0.357451</td>\n",
       "      <td>-1.319617</td>\n",
       "      <td>-0.521895</td>\n",
       "      <td>-0.255624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.139351</td>\n",
       "      <td>-0.633330</td>\n",
       "      <td>-0.616855</td>\n",
       "      <td>0.846722</td>\n",
       "      <td>0.984656</td>\n",
       "      <td>0.783823</td>\n",
       "      <td>0.792962</td>\n",
       "      <td>0.569030</td>\n",
       "      <td>0.131523</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416154</td>\n",
       "      <td>0.070638</td>\n",
       "      <td>-0.049535</td>\n",
       "      <td>-1.450612</td>\n",
       "      <td>-0.529286</td>\n",
       "      <td>-0.258399</td>\n",
       "      <td>1.859715</td>\n",
       "      <td>-0.160022</td>\n",
       "      <td>0.273241</td>\n",
       "      <td>2.151323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2.093198</td>\n",
       "      <td>-1.511883</td>\n",
       "      <td>1.159381</td>\n",
       "      <td>0.973102</td>\n",
       "      <td>-0.779093</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>-0.457633</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>1.509131</td>\n",
       "      <td>0.605606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682287</td>\n",
       "      <td>-0.426561</td>\n",
       "      <td>-1.624860</td>\n",
       "      <td>-0.077222</td>\n",
       "      <td>0.801357</td>\n",
       "      <td>0.492039</td>\n",
       "      <td>1.814402</td>\n",
       "      <td>-0.253188</td>\n",
       "      <td>-0.160752</td>\n",
       "      <td>-0.233309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRCA1_genomic  BRCA1_transcriptomic  BRCA1_proteomic  BRCA2_genomic  \\\n",
       "0         -0.694713             -0.409282        -0.524088       0.152355   \n",
       "1          1.592025             -0.587738        -1.443201       0.638187   \n",
       "2          0.269784              0.011594        -1.025943       0.034849   \n",
       "3         -1.187765             -0.397323         0.534365       0.091094   \n",
       "4          2.412615              0.784604        -0.019260      -0.262891   \n",
       "...             ...                   ...              ...            ...   \n",
       "4995      -1.232540             -0.684492         0.457324       2.098221   \n",
       "4996      -2.403669              1.392456         0.672293      -1.500477   \n",
       "4997       0.765402              1.073413         0.498690      -1.942498   \n",
       "4998       0.139351             -0.633330        -0.616855       0.846722   \n",
       "4999       2.093198             -1.511883         1.159381       0.973102   \n",
       "\n",
       "      BRCA2_transcriptomic  BRCA2_proteomic  TP53_genomic  \\\n",
       "0                 0.242705         1.121031      0.000207   \n",
       "1                 1.744311         0.663598      0.204798   \n",
       "2                -1.334827        -0.124077      1.636105   \n",
       "3                -0.851540         0.006273     -1.531535   \n",
       "4                 0.022466        -0.008800     -1.180813   \n",
       "...                    ...              ...           ...   \n",
       "4995             -0.138082         0.591136     -0.106971   \n",
       "4996             -1.478777         1.672266      0.583625   \n",
       "4997             -0.155422        -1.155708     -0.202606   \n",
       "4998              0.984656         0.783823      0.792962   \n",
       "4999             -0.779093         0.203236     -0.457633   \n",
       "\n",
       "      TP53_transcriptomic  TP53_proteomic  ATM_genomic  ...  CDH1_proteomic  \\\n",
       "0               -0.009300       -0.327895     0.155191  ...       -0.010190   \n",
       "1                0.409141        1.414841    -0.874199  ...       -1.538794   \n",
       "2                0.822859       -0.923119    -0.072429  ...       -0.292375   \n",
       "3                1.150267       -0.205284     1.118550  ...        0.661383   \n",
       "4                1.114322        0.715381     0.718186  ...       -0.032811   \n",
       "...                   ...             ...          ...  ...             ...   \n",
       "4995             1.942246       -0.203036     0.094621  ...        2.202952   \n",
       "4996            -0.834185       -2.266052    -0.350778  ...        0.956554   \n",
       "4997             0.980004        0.305151     1.148091  ...       -1.633039   \n",
       "4998             0.569030        0.131523    -0.175380  ...       -0.416154   \n",
       "4999             0.185689        1.509131     0.605606  ...        0.682287   \n",
       "\n",
       "      ARID1A_genomic  ARID1A_transcriptomic  ARID1A_proteomic  KRAS_genomic  \\\n",
       "0          -1.208506               0.299469          1.002222      0.593181   \n",
       "1          -0.057381               0.216725          1.056715     -0.979691   \n",
       "2          -0.047902               1.698181         -0.379144      0.561112   \n",
       "3          -2.662336               0.540007          0.313300      0.497026   \n",
       "4           2.155470              -0.495627          1.296774     -0.885340   \n",
       "...              ...                    ...               ...           ...   \n",
       "4995       -0.957253               0.539574          0.288545      0.528159   \n",
       "4996       -0.070926              -0.941599          0.517374      0.001503   \n",
       "4997        1.064273               1.706536          1.283887      0.271824   \n",
       "4998        0.070638              -0.049535         -1.450612     -0.529286   \n",
       "4999       -0.426561              -1.624860         -0.077222      0.801357   \n",
       "\n",
       "      KRAS_transcriptomic  KRAS_proteomic  SMAD4_genomic  \\\n",
       "0                0.059304        0.565291      -0.223245   \n",
       "1                0.415395       -0.175845       0.812034   \n",
       "2                0.349701        0.062074      -0.958112   \n",
       "3               -1.928427        0.292830      -0.542501   \n",
       "4               -1.536663        0.987496      -0.218814   \n",
       "...                   ...             ...            ...   \n",
       "4995            -0.284904       -0.592256       0.226493   \n",
       "4996             1.050505        0.133337      -1.437188   \n",
       "4997             1.539460        0.357451      -1.319617   \n",
       "4998            -0.258399        1.859715      -0.160022   \n",
       "4999             0.492039        1.814402      -0.253188   \n",
       "\n",
       "      SMAD4_transcriptomic  SMAD4_proteomic  \n",
       "0                 1.044175         1.347181  \n",
       "1                -0.615397         0.401048  \n",
       "2                 0.523665        -1.925637  \n",
       "3                 1.602190         0.361721  \n",
       "4                 1.271249         1.470893  \n",
       "...                    ...              ...  \n",
       "4995             -0.456029        -2.331638  \n",
       "4996             -0.496744        -1.157195  \n",
       "4997             -0.521895        -0.255624  \n",
       "4998              0.273241         2.151323  \n",
       "4999             -0.160752        -0.233309  \n",
       "\n",
       "[5000 rows x 60 columns]"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = IterativeImputer(random_state=42)\n",
    "X_imputed = imputer.fit_transform(x)\n",
    "X_imputed = pd.DataFrame(X_imputed, columns=original_columns)\n",
    "X_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "8499e001-9116-4ab8-9863-fe7ab2786661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "dc455425-4198-4238-a2ec-ad5e6466a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {'sensitive': 0, 'resistant': 1}\n",
    "df['resistance_label_encoded'] = df['resistance_label'].map(category_mapping)\n",
    "y=df['resistance_label_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24a20d-1293-43b9-a0f0-2daea269c13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "b08518ec-eeb6-4434-96a8-024a9ed6560e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     0.0\n",
       "1     0.0\n",
       "2     1.0\n",
       "3     1.0\n",
       "4     0.0\n",
       "...   ...\n",
       "4995  1.0\n",
       "4996  1.0\n",
       "4997  0.0\n",
       "4998  0.0\n",
       "4999  0.0\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply the imputer to the target (y)\n",
    "y_imputed = imputer.fit_transform(y.values.reshape(-1, 1)).ravel() \n",
    "pd.DataFrame(y_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "f45999f2-4997-45f4-ae93-5bca0d5fe409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRCA1_genomic</th>\n",
       "      <th>BRCA1_transcriptomic</th>\n",
       "      <th>BRCA1_proteomic</th>\n",
       "      <th>BRCA2_genomic</th>\n",
       "      <th>BRCA2_transcriptomic</th>\n",
       "      <th>BRCA2_proteomic</th>\n",
       "      <th>TP53_genomic</th>\n",
       "      <th>TP53_transcriptomic</th>\n",
       "      <th>TP53_proteomic</th>\n",
       "      <th>ATM_genomic</th>\n",
       "      <th>...</th>\n",
       "      <th>CDH1_proteomic</th>\n",
       "      <th>ARID1A_genomic</th>\n",
       "      <th>ARID1A_transcriptomic</th>\n",
       "      <th>ARID1A_proteomic</th>\n",
       "      <th>KRAS_genomic</th>\n",
       "      <th>KRAS_transcriptomic</th>\n",
       "      <th>KRAS_proteomic</th>\n",
       "      <th>SMAD4_genomic</th>\n",
       "      <th>SMAD4_transcriptomic</th>\n",
       "      <th>SMAD4_proteomic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.694713</td>\n",
       "      <td>-0.409282</td>\n",
       "      <td>-0.524088</td>\n",
       "      <td>0.152355</td>\n",
       "      <td>0.242705</td>\n",
       "      <td>1.121031</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>-0.327895</td>\n",
       "      <td>0.155191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>-1.208506</td>\n",
       "      <td>0.299469</td>\n",
       "      <td>1.002222</td>\n",
       "      <td>0.593181</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.565291</td>\n",
       "      <td>-0.223245</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>1.347181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.592025</td>\n",
       "      <td>-0.587738</td>\n",
       "      <td>-1.443201</td>\n",
       "      <td>0.638187</td>\n",
       "      <td>1.744311</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.409141</td>\n",
       "      <td>1.414841</td>\n",
       "      <td>-0.874199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.538794</td>\n",
       "      <td>-0.057381</td>\n",
       "      <td>0.216725</td>\n",
       "      <td>1.056715</td>\n",
       "      <td>-0.979691</td>\n",
       "      <td>0.415395</td>\n",
       "      <td>-0.175845</td>\n",
       "      <td>0.812034</td>\n",
       "      <td>-0.615397</td>\n",
       "      <td>0.401048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269784</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>-1.025943</td>\n",
       "      <td>0.034849</td>\n",
       "      <td>-1.334827</td>\n",
       "      <td>-0.124077</td>\n",
       "      <td>1.636105</td>\n",
       "      <td>0.822859</td>\n",
       "      <td>-0.923119</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292375</td>\n",
       "      <td>-0.047902</td>\n",
       "      <td>1.698181</td>\n",
       "      <td>-0.379144</td>\n",
       "      <td>0.561112</td>\n",
       "      <td>0.349701</td>\n",
       "      <td>0.062074</td>\n",
       "      <td>-0.958112</td>\n",
       "      <td>0.523665</td>\n",
       "      <td>-1.925637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.187765</td>\n",
       "      <td>-0.397323</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>0.091094</td>\n",
       "      <td>-0.851540</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>-1.531535</td>\n",
       "      <td>1.150267</td>\n",
       "      <td>-0.205284</td>\n",
       "      <td>1.118550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661383</td>\n",
       "      <td>-2.662336</td>\n",
       "      <td>0.540007</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.497026</td>\n",
       "      <td>-1.928427</td>\n",
       "      <td>0.292830</td>\n",
       "      <td>-0.542501</td>\n",
       "      <td>1.602190</td>\n",
       "      <td>0.361721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.412615</td>\n",
       "      <td>0.784604</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.262891</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>-1.180813</td>\n",
       "      <td>1.114322</td>\n",
       "      <td>0.715381</td>\n",
       "      <td>0.718186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032811</td>\n",
       "      <td>2.155470</td>\n",
       "      <td>-0.495627</td>\n",
       "      <td>1.296774</td>\n",
       "      <td>-0.885340</td>\n",
       "      <td>-1.536663</td>\n",
       "      <td>0.987496</td>\n",
       "      <td>-0.218814</td>\n",
       "      <td>1.271249</td>\n",
       "      <td>1.470893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-1.232540</td>\n",
       "      <td>-0.684492</td>\n",
       "      <td>0.457324</td>\n",
       "      <td>2.098221</td>\n",
       "      <td>-0.138082</td>\n",
       "      <td>0.591136</td>\n",
       "      <td>-0.106971</td>\n",
       "      <td>1.942246</td>\n",
       "      <td>-0.203036</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>...</td>\n",
       "      <td>2.202952</td>\n",
       "      <td>-0.957253</td>\n",
       "      <td>0.539574</td>\n",
       "      <td>0.288545</td>\n",
       "      <td>0.528159</td>\n",
       "      <td>-0.284904</td>\n",
       "      <td>-0.592256</td>\n",
       "      <td>0.226493</td>\n",
       "      <td>-0.456029</td>\n",
       "      <td>-2.331638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-2.403669</td>\n",
       "      <td>1.392456</td>\n",
       "      <td>0.672293</td>\n",
       "      <td>-1.500477</td>\n",
       "      <td>-1.478777</td>\n",
       "      <td>1.672266</td>\n",
       "      <td>0.583625</td>\n",
       "      <td>-0.834185</td>\n",
       "      <td>-2.266052</td>\n",
       "      <td>-0.350778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956554</td>\n",
       "      <td>-0.070926</td>\n",
       "      <td>-0.941599</td>\n",
       "      <td>0.517374</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>1.050505</td>\n",
       "      <td>0.133337</td>\n",
       "      <td>-1.437188</td>\n",
       "      <td>-0.496744</td>\n",
       "      <td>-1.157195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.765402</td>\n",
       "      <td>1.073413</td>\n",
       "      <td>0.498690</td>\n",
       "      <td>-1.942498</td>\n",
       "      <td>-0.155422</td>\n",
       "      <td>-1.155708</td>\n",
       "      <td>-0.202606</td>\n",
       "      <td>0.980004</td>\n",
       "      <td>0.305151</td>\n",
       "      <td>1.148091</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.633039</td>\n",
       "      <td>1.064273</td>\n",
       "      <td>1.706536</td>\n",
       "      <td>1.283887</td>\n",
       "      <td>0.271824</td>\n",
       "      <td>1.539460</td>\n",
       "      <td>0.357451</td>\n",
       "      <td>-1.319617</td>\n",
       "      <td>-0.521895</td>\n",
       "      <td>-0.255624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.139351</td>\n",
       "      <td>-0.633330</td>\n",
       "      <td>-0.616855</td>\n",
       "      <td>0.846722</td>\n",
       "      <td>0.984656</td>\n",
       "      <td>0.783823</td>\n",
       "      <td>0.792962</td>\n",
       "      <td>0.569030</td>\n",
       "      <td>0.131523</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416154</td>\n",
       "      <td>0.070638</td>\n",
       "      <td>-0.049535</td>\n",
       "      <td>-1.450612</td>\n",
       "      <td>-0.529286</td>\n",
       "      <td>-0.258399</td>\n",
       "      <td>1.859715</td>\n",
       "      <td>-0.160022</td>\n",
       "      <td>0.273241</td>\n",
       "      <td>2.151323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2.093198</td>\n",
       "      <td>-1.511883</td>\n",
       "      <td>1.159381</td>\n",
       "      <td>0.973102</td>\n",
       "      <td>-0.779093</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>-0.457633</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>1.509131</td>\n",
       "      <td>0.605606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682287</td>\n",
       "      <td>-0.426561</td>\n",
       "      <td>-1.624860</td>\n",
       "      <td>-0.077222</td>\n",
       "      <td>0.801357</td>\n",
       "      <td>0.492039</td>\n",
       "      <td>1.814402</td>\n",
       "      <td>-0.253188</td>\n",
       "      <td>-0.160752</td>\n",
       "      <td>-0.233309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRCA1_genomic  BRCA1_transcriptomic  BRCA1_proteomic  BRCA2_genomic  \\\n",
       "0         -0.694713             -0.409282        -0.524088       0.152355   \n",
       "1          1.592025             -0.587738        -1.443201       0.638187   \n",
       "2          0.269784              0.011594        -1.025943       0.034849   \n",
       "3         -1.187765             -0.397323         0.534365       0.091094   \n",
       "4          2.412615              0.784604        -0.019260      -0.262891   \n",
       "...             ...                   ...              ...            ...   \n",
       "4995      -1.232540             -0.684492         0.457324       2.098221   \n",
       "4996      -2.403669              1.392456         0.672293      -1.500477   \n",
       "4997       0.765402              1.073413         0.498690      -1.942498   \n",
       "4998       0.139351             -0.633330        -0.616855       0.846722   \n",
       "4999       2.093198             -1.511883         1.159381       0.973102   \n",
       "\n",
       "      BRCA2_transcriptomic  BRCA2_proteomic  TP53_genomic  \\\n",
       "0                 0.242705         1.121031      0.000207   \n",
       "1                 1.744311         0.663598      0.204798   \n",
       "2                -1.334827        -0.124077      1.636105   \n",
       "3                -0.851540         0.006273     -1.531535   \n",
       "4                 0.022466        -0.008800     -1.180813   \n",
       "...                    ...              ...           ...   \n",
       "4995             -0.138082         0.591136     -0.106971   \n",
       "4996             -1.478777         1.672266      0.583625   \n",
       "4997             -0.155422        -1.155708     -0.202606   \n",
       "4998              0.984656         0.783823      0.792962   \n",
       "4999             -0.779093         0.203236     -0.457633   \n",
       "\n",
       "      TP53_transcriptomic  TP53_proteomic  ATM_genomic  ...  CDH1_proteomic  \\\n",
       "0               -0.009300       -0.327895     0.155191  ...       -0.010190   \n",
       "1                0.409141        1.414841    -0.874199  ...       -1.538794   \n",
       "2                0.822859       -0.923119    -0.072429  ...       -0.292375   \n",
       "3                1.150267       -0.205284     1.118550  ...        0.661383   \n",
       "4                1.114322        0.715381     0.718186  ...       -0.032811   \n",
       "...                   ...             ...          ...  ...             ...   \n",
       "4995             1.942246       -0.203036     0.094621  ...        2.202952   \n",
       "4996            -0.834185       -2.266052    -0.350778  ...        0.956554   \n",
       "4997             0.980004        0.305151     1.148091  ...       -1.633039   \n",
       "4998             0.569030        0.131523    -0.175380  ...       -0.416154   \n",
       "4999             0.185689        1.509131     0.605606  ...        0.682287   \n",
       "\n",
       "      ARID1A_genomic  ARID1A_transcriptomic  ARID1A_proteomic  KRAS_genomic  \\\n",
       "0          -1.208506               0.299469          1.002222      0.593181   \n",
       "1          -0.057381               0.216725          1.056715     -0.979691   \n",
       "2          -0.047902               1.698181         -0.379144      0.561112   \n",
       "3          -2.662336               0.540007          0.313300      0.497026   \n",
       "4           2.155470              -0.495627          1.296774     -0.885340   \n",
       "...              ...                    ...               ...           ...   \n",
       "4995       -0.957253               0.539574          0.288545      0.528159   \n",
       "4996       -0.070926              -0.941599          0.517374      0.001503   \n",
       "4997        1.064273               1.706536          1.283887      0.271824   \n",
       "4998        0.070638              -0.049535         -1.450612     -0.529286   \n",
       "4999       -0.426561              -1.624860         -0.077222      0.801357   \n",
       "\n",
       "      KRAS_transcriptomic  KRAS_proteomic  SMAD4_genomic  \\\n",
       "0                0.059304        0.565291      -0.223245   \n",
       "1                0.415395       -0.175845       0.812034   \n",
       "2                0.349701        0.062074      -0.958112   \n",
       "3               -1.928427        0.292830      -0.542501   \n",
       "4               -1.536663        0.987496      -0.218814   \n",
       "...                   ...             ...            ...   \n",
       "4995            -0.284904       -0.592256       0.226493   \n",
       "4996             1.050505        0.133337      -1.437188   \n",
       "4997             1.539460        0.357451      -1.319617   \n",
       "4998            -0.258399        1.859715      -0.160022   \n",
       "4999             0.492039        1.814402      -0.253188   \n",
       "\n",
       "      SMAD4_transcriptomic  SMAD4_proteomic  \n",
       "0                 1.044175         1.347181  \n",
       "1                -0.615397         0.401048  \n",
       "2                 0.523665        -1.925637  \n",
       "3                 1.602190         0.361721  \n",
       "4                 1.271249         1.470893  \n",
       "...                    ...              ...  \n",
       "4995             -0.456029        -2.331638  \n",
       "4996             -0.496744        -1.157195  \n",
       "4997             -0.521895        -0.255624  \n",
       "4998              0.273241         2.151323  \n",
       "4999             -0.160752        -0.233309  \n",
       "\n",
       "[5000 rows x 60 columns]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your dataset\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encoding the 'gender' column\n",
    "df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "df_encoded = pd.get_dummies(df, columns=['ethnicity', 'chemotherapy_type', 'tumor_stage', 'clinical_outcome'], drop_first=False)\n",
    "df_encoded.columns\n",
    "X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "170f39cb-d007-45bc-a053-df641bb62f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>treatment_duration</th>\n",
       "      <th>ethnicity_Asian</th>\n",
       "      <th>ethnicity_Black</th>\n",
       "      <th>ethnicity_Caucasian</th>\n",
       "      <th>ethnicity_Hispanic</th>\n",
       "      <th>chemotherapy_type_Regimen A</th>\n",
       "      <th>chemotherapy_type_Regimen B</th>\n",
       "      <th>chemotherapy_type_Regimen C</th>\n",
       "      <th>...</th>\n",
       "      <th>ARID1A_genomic</th>\n",
       "      <th>ARID1A_transcriptomic</th>\n",
       "      <th>ARID1A_proteomic</th>\n",
       "      <th>KRAS_genomic</th>\n",
       "      <th>KRAS_transcriptomic</th>\n",
       "      <th>KRAS_proteomic</th>\n",
       "      <th>SMAD4_genomic</th>\n",
       "      <th>SMAD4_transcriptomic</th>\n",
       "      <th>SMAD4_proteomic</th>\n",
       "      <th>resistance_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.208506</td>\n",
       "      <td>0.299469</td>\n",
       "      <td>1.002222</td>\n",
       "      <td>0.593181</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.565291</td>\n",
       "      <td>-0.223245</td>\n",
       "      <td>1.044175</td>\n",
       "      <td>1.347181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057381</td>\n",
       "      <td>0.216725</td>\n",
       "      <td>1.056715</td>\n",
       "      <td>-0.979691</td>\n",
       "      <td>0.415395</td>\n",
       "      <td>-0.175845</td>\n",
       "      <td>0.812034</td>\n",
       "      <td>-0.615397</td>\n",
       "      <td>0.401048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047902</td>\n",
       "      <td>1.698181</td>\n",
       "      <td>-0.379144</td>\n",
       "      <td>0.561112</td>\n",
       "      <td>0.349701</td>\n",
       "      <td>0.062074</td>\n",
       "      <td>-0.958112</td>\n",
       "      <td>0.523665</td>\n",
       "      <td>-1.925637</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.662336</td>\n",
       "      <td>0.540007</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.497026</td>\n",
       "      <td>-1.928427</td>\n",
       "      <td>0.292830</td>\n",
       "      <td>-0.542501</td>\n",
       "      <td>1.602190</td>\n",
       "      <td>0.361721</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.155470</td>\n",
       "      <td>-0.495627</td>\n",
       "      <td>1.296774</td>\n",
       "      <td>-0.885340</td>\n",
       "      <td>-1.536663</td>\n",
       "      <td>0.987496</td>\n",
       "      <td>-0.218814</td>\n",
       "      <td>1.271249</td>\n",
       "      <td>1.470893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.957253</td>\n",
       "      <td>0.539574</td>\n",
       "      <td>0.288545</td>\n",
       "      <td>0.528159</td>\n",
       "      <td>-0.284904</td>\n",
       "      <td>-0.592256</td>\n",
       "      <td>0.226493</td>\n",
       "      <td>-0.456029</td>\n",
       "      <td>-2.331638</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070926</td>\n",
       "      <td>-0.941599</td>\n",
       "      <td>0.517374</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>1.050505</td>\n",
       "      <td>0.133337</td>\n",
       "      <td>-1.437188</td>\n",
       "      <td>-0.496744</td>\n",
       "      <td>-1.157195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.064273</td>\n",
       "      <td>1.706536</td>\n",
       "      <td>1.283887</td>\n",
       "      <td>0.271824</td>\n",
       "      <td>1.539460</td>\n",
       "      <td>0.357451</td>\n",
       "      <td>-1.319617</td>\n",
       "      <td>-0.521895</td>\n",
       "      <td>-0.255624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070638</td>\n",
       "      <td>-0.049535</td>\n",
       "      <td>-1.450612</td>\n",
       "      <td>-0.529286</td>\n",
       "      <td>-0.258399</td>\n",
       "      <td>1.859715</td>\n",
       "      <td>-0.160022</td>\n",
       "      <td>0.273241</td>\n",
       "      <td>2.151323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426561</td>\n",
       "      <td>-1.624860</td>\n",
       "      <td>-0.077222</td>\n",
       "      <td>0.801357</td>\n",
       "      <td>0.492039</td>\n",
       "      <td>1.814402</td>\n",
       "      <td>-0.253188</td>\n",
       "      <td>-0.160752</td>\n",
       "      <td>-0.233309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  treatment_duration  ethnicity_Asian  ethnicity_Black  \\\n",
       "0      30       1                   7                0                0   \n",
       "1      72       0                  10                1                0   \n",
       "2      71       1                  11                1                0   \n",
       "3      60       0                   3                0                1   \n",
       "4      40       1                   4                0                1   \n",
       "...   ...     ...                 ...              ...              ...   \n",
       "4995   48       0                   4                1                0   \n",
       "4996   53       1                   3                0                0   \n",
       "4997   69       0                  10                0                1   \n",
       "4998   71       1                   5                0                0   \n",
       "4999   46       1                   6                0                0   \n",
       "\n",
       "      ethnicity_Caucasian  ethnicity_Hispanic  chemotherapy_type_Regimen A  \\\n",
       "0                       1                   0                            1   \n",
       "1                       0                   0                            0   \n",
       "2                       0                   0                            1   \n",
       "3                       0                   0                            0   \n",
       "4                       0                   0                            0   \n",
       "...                   ...                 ...                          ...   \n",
       "4995                    0                   0                            0   \n",
       "4996                    0                   1                            0   \n",
       "4997                    0                   0                            0   \n",
       "4998                    0                   1                            1   \n",
       "4999                    0                   1                            0   \n",
       "\n",
       "      chemotherapy_type_Regimen B  chemotherapy_type_Regimen C  ...  \\\n",
       "0                               0                            0  ...   \n",
       "1                               0                            1  ...   \n",
       "2                               0                            0  ...   \n",
       "3                               1                            0  ...   \n",
       "4                               0                            1  ...   \n",
       "...                           ...                          ...  ...   \n",
       "4995                            0                            1  ...   \n",
       "4996                            0                            1  ...   \n",
       "4997                            0                            1  ...   \n",
       "4998                            0                            0  ...   \n",
       "4999                            0                            1  ...   \n",
       "\n",
       "      ARID1A_genomic  ARID1A_transcriptomic  ARID1A_proteomic  KRAS_genomic  \\\n",
       "0          -1.208506               0.299469          1.002222      0.593181   \n",
       "1          -0.057381               0.216725          1.056715     -0.979691   \n",
       "2          -0.047902               1.698181         -0.379144      0.561112   \n",
       "3          -2.662336               0.540007          0.313300      0.497026   \n",
       "4           2.155470              -0.495627          1.296774     -0.885340   \n",
       "...              ...                    ...               ...           ...   \n",
       "4995       -0.957253               0.539574          0.288545      0.528159   \n",
       "4996       -0.070926              -0.941599          0.517374      0.001503   \n",
       "4997        1.064273               1.706536          1.283887      0.271824   \n",
       "4998        0.070638              -0.049535         -1.450612     -0.529286   \n",
       "4999       -0.426561              -1.624860         -0.077222      0.801357   \n",
       "\n",
       "      KRAS_transcriptomic  KRAS_proteomic  SMAD4_genomic  \\\n",
       "0                0.059304        0.565291      -0.223245   \n",
       "1                0.415395       -0.175845       0.812034   \n",
       "2                0.349701        0.062074      -0.958112   \n",
       "3               -1.928427        0.292830      -0.542501   \n",
       "4               -1.536663        0.987496      -0.218814   \n",
       "...                   ...             ...            ...   \n",
       "4995            -0.284904       -0.592256       0.226493   \n",
       "4996             1.050505        0.133337      -1.437188   \n",
       "4997             1.539460        0.357451      -1.319617   \n",
       "4998            -0.258399        1.859715      -0.160022   \n",
       "4999             0.492039        1.814402      -0.253188   \n",
       "\n",
       "      SMAD4_transcriptomic  SMAD4_proteomic  resistance_label  \n",
       "0                 1.044175         1.347181               0.0  \n",
       "1                -0.615397         0.401048               0.0  \n",
       "2                 0.523665        -1.925637               1.0  \n",
       "3                 1.602190         0.361721               1.0  \n",
       "4                 1.271249         1.470893               0.0  \n",
       "...                    ...              ...               ...  \n",
       "4995             -0.456029        -2.331638               1.0  \n",
       "4996             -0.496744        -1.157195               1.0  \n",
       "4997             -0.521895        -0.255624               0.0  \n",
       "4998              0.273241         2.151323               0.0  \n",
       "4999             -0.160752        -0.233309               0.0  \n",
       "\n",
       "[5000 rows x 78 columns]"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode other categorical columns\n",
    "final_df = pd.concat([df_encoded[['age',\n",
    "       'gender', 'treatment_duration',\n",
    "       'ethnicity_Asian', 'ethnicity_Black', 'ethnicity_Caucasian',\n",
    "       'ethnicity_Hispanic', 'chemotherapy_type_Regimen A',\n",
    "       'chemotherapy_type_Regimen B', 'chemotherapy_type_Regimen C',\n",
    "       'tumor_stage_Stage I', 'tumor_stage_Stage II', 'tumor_stage_Stage III',\n",
    "       'tumor_stage_Stage IV', 'clinical_outcome_Progression',\n",
    "       'clinical_outcome_Remission', 'clinical_outcome_Stable']], X_imputed], axis=1)\n",
    "final_df['resistance_label'] = y_imputed\n",
    "final_df[[\n",
    "        'ethnicity_Asian', 'ethnicity_Black', 'ethnicity_Caucasian',\n",
    "       'ethnicity_Hispanic', 'chemotherapy_type_Regimen A',\n",
    "       'chemotherapy_type_Regimen B', 'chemotherapy_type_Regimen C',\n",
    "       'tumor_stage_Stage I', 'tumor_stage_Stage II', 'tumor_stage_Stage III',\n",
    "       'tumor_stage_Stage IV', 'clinical_outcome_Progression',\n",
    "       'clinical_outcome_Remission', 'clinical_outcome_Stable']]=final_df[[\n",
    "        'ethnicity_Asian', 'ethnicity_Black', 'ethnicity_Caucasian',\n",
    "       'ethnicity_Hispanic', 'chemotherapy_type_Regimen A',\n",
    "       'chemotherapy_type_Regimen B', 'chemotherapy_type_Regimen C',\n",
    "       'tumor_stage_Stage I', 'tumor_stage_Stage II', 'tumor_stage_Stage III',\n",
    "       'tumor_stage_Stage IV', 'clinical_outcome_Progression',\n",
    "       'clinical_outcome_Remission', 'clinical_outcome_Stable']].astype(int)\n",
    "\n",
    "#final_df = final_df.astype(int)\n",
    "\n",
    "# Display the encoded dataframe\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "7abb3a94-ff33-4028-be5d-e4d08108792f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resistance_label\n",
       "0.0    3685\n",
       "1.0    1315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"resistance_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "3c40cc26-da69-4f6e-999d-dc7ecb3a0e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                     0\n",
       "gender                  0\n",
       "treatment_duration      0\n",
       "ethnicity_Asian         0\n",
       "ethnicity_Black         0\n",
       "                       ..\n",
       "KRAS_proteomic          0\n",
       "SMAD4_genomic           0\n",
       "SMAD4_transcriptomic    0\n",
       "SMAD4_proteomic         0\n",
       "resistance_label        0\n",
       "Length: 78, dtype: int64"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "692881b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop('resistance_label', axis=1)  # Features\n",
    "y = final_df['resistance_label']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "6fe261d9-e6f8-4924-a03f-f29b578855ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "48d4814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d7e6b",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "6b9bcf34-78df-4ca9-adcb-8a9a2b07b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    -0.007135\n",
       "gender                 -0.014514\n",
       "treatment_duration     -0.020110\n",
       "ethnicity_Asian         0.025757\n",
       "ethnicity_Black        -0.041743\n",
       "                          ...   \n",
       "KRAS_transcriptomic    -0.023200\n",
       "KRAS_proteomic          0.008377\n",
       "SMAD4_genomic          -0.007035\n",
       "SMAD4_transcriptomic   -0.030892\n",
       "SMAD4_proteomic        -0.075497\n",
       "Name: resistance_label, Length: 77, dtype: float64"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = final_df.corr()['resistance_label'].drop('resistance_label')\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "d1cd3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AA\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "a7897e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      "[[705  37]\n",
      " [ 63 195]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       742\n",
      "         1.0       0.84      0.76      0.80       258\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.88      0.85      0.86      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "1866f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9155\n",
      "Testing Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      "[[705  37]\n",
      " [ 63 195]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       742\n",
      "         1.0       0.84      0.76      0.80       258\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.88      0.85      0.86      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = model.score(X_train, y_train)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c8ac1a",
   "metadata": {},
   "source": [
    "testing using svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "8191ace2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.91\n",
      "Test Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(C=1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "# Step 4: Train a Support Vector Machine (SVM) model\n",
    "#model = SVC(kernel='linear', C=1)  # Linear kernel and regularization strength C=1\n",
    "#model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "f8595129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      "[[705  37]\n",
      " [ 63 195]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       742\n",
      "         1.0       0.84      0.76      0.80       258\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.88      0.85      0.86      1000\n",
      "weighted avg       0.90      0.90      0.90      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "35224ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Scores: [0.913 0.911 0.901 0.879 0.896]\n",
      "Average Cross-validation Score: 0.9000\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(model, X_scaled, y_imputed, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "print(f\"Cross-validation Scores: {cv_scores}\")\n",
    "print(f\"Average Cross-validation Score: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "53e4f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['resistance_label'])\n",
    "y = final_df['resistance_label']\n",
    "\n",
    "# Balance the dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "6b65b343-0e31-4bbb-b617-baf3e0b9279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.5, early_stopping=True, hidden_layer_sizes=(16, 8),\n",
       "              max_iter=500, random_state=42, validation_fraction=0.2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(alpha=0.5, early_stopping=True, hidden_layer_sizes=(16, 8),\n",
       "              max_iter=500, random_state=42, validation_fraction=0.2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.5, early_stopping=True, hidden_layer_sizes=(16, 8),\n",
       "              max_iter=500, random_state=42, validation_fraction=0.2)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full)\n",
    "\n",
    "# Adjust MLP structure with increased dropout and regularization\n",
    "model = MLPClassifier(hidden_layer_sizes=(16, 8), activation='relu', solver='adam', \n",
    "                      max_iter=500, random_state=42, alpha=0.5, early_stopping=True,\n",
    "                      validation_fraction=0.2)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "4a9eea06-0cf3-41a5-bbf2-87758188f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.87%\n",
      "Validation Accuracy: 98.81%\n",
      "Test Accuracy: 98.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99       737\n",
      "         1.0       0.98      0.99      0.99       737\n",
      "\n",
      "    accuracy                           0.99      1474\n",
      "   macro avg       0.99      0.99      0.99      1474\n",
      "weighted avg       0.99      0.99      0.99      1474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = model.score(X_train, y_train)\n",
    "val_accuracy = model.score(X_val, y_val)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "956f3645-0e2e-41e1-9ba3-917aa57cbe1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_curve = model.loss_curve_\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_curve, label='Training Loss', marker='o')\n",
    "plt.title('Loss Curve for MLPClassifier')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "fc439dbe-be47-4585-8ead-88b22067ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize individual classifiers\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "svm  = LinearSVC(C=1, random_state=42)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(16, 8), activation='relu', solver='adam', \n",
    "                      max_iter=500, random_state=42, alpha=0.5, early_stopping=True,\n",
    "                      validation_fraction=0.2)\n",
    "\n",
    "# Create an ensemble using VotingClassifier\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('LogReg', log_reg),\n",
    "        ('SVM', svm),\n",
    "        ('MLP', mlp)\n",
    "    ],\n",
    "    voting='hard'  # Use 'hard' for majority vote or 'soft' for averaged probabilities\n",
    ")\n",
    "\n",
    "# Train the ensemble\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e8344ce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 4: Visualize PCA-reduced data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(X_pca[ :\u001b[38;5;241m1\u001b[39m],y_imputed , c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA of Synthetic Data: Linear Separation Check\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrincipal Component 1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2862\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[0;32m   2858\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[0;32m   2859\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2860\u001b[0m         vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2861\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, plotnonfinite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2862\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[0;32m   2863\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39ms, c\u001b[38;5;241m=\u001b[39mc, marker\u001b[38;5;241m=\u001b[39mmarker, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   2864\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin, vmax\u001b[38;5;241m=\u001b[39mvmax, alpha\u001b[38;5;241m=\u001b[39malpha, linewidths\u001b[38;5;241m=\u001b[39mlinewidths,\n\u001b[0;32m   2865\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39medgecolors, plotnonfinite\u001b[38;5;241m=\u001b[39mplotnonfinite,\n\u001b[0;32m   2866\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2867\u001b[0m     sci(__ret)\n\u001b[0;32m   2868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1444\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1445\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1446\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:4584\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4582\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m   4583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m-> 4584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4587\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_internal.classic_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   4588\u001b[0m          mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_imputed)\n",
    "\n",
    "# Step 4: Visualize PCA-reduced data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[ :1],y_imputed , c='red', cmap='coolwarm', edgecolors='k', alpha=0.8)\n",
    "plt.title('PCA of Synthetic Data: Linear Separation Check')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
